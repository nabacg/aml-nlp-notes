{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                datasets.py              \u001b[31mexample.py\u001b[m\u001b[m\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m              \u001b[31mdownload_cornell.sh\u001b[m\u001b[m      seq2seq-lang-model.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                     \u001b[31mdownload_opensubs.sh\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "\r\n",
      "mkdir -p data/cornell\r\n",
      "cd data/cornell\r\n",
      "wget https://github.com/Conchylicultor/DeepQA/raw/master/data/cornell/movie_conversations.txt\r\n",
      "wget https://github.com/Conchylicultor/DeepQA/raw/master/data/cornell/movie_lines.txt\r\n"
     ]
    }
   ],
   "source": [
    "! cat download_cornell.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-22 18:13:55--  https://github.com/Conchylicultor/DeepQA/raw/master/data/cornell/movie_conversations.txt\n",
      "Resolving github.com (github.com)... 140.82.118.4\n",
      "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Conchylicultor/DeepQA/master/data/cornell/movie_conversations.txt [following]\n",
      "--2019-06-22 18:13:55--  https://raw.githubusercontent.com/Conchylicultor/DeepQA/master/data/cornell/movie_conversations.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6760930 (6.4M) [text/plain]\n",
      "Saving to: ‘movie_conversations.txt’\n",
      "\n",
      "movie_conversations 100%[===================>]   6.45M  1.87MB/s    in 3.4s    \n",
      "\n",
      "2019-06-22 18:13:59 (1.87 MB/s) - ‘movie_conversations.txt’ saved [6760930/6760930]\n",
      "\n",
      "--2019-06-22 18:13:59--  https://github.com/Conchylicultor/DeepQA/raw/master/data/cornell/movie_lines.txt\n",
      "Resolving github.com (github.com)... 140.82.118.4\n",
      "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Conchylicultor/DeepQA/master/data/cornell/movie_lines.txt [following]\n",
      "--2019-06-22 18:14:00--  https://raw.githubusercontent.com/Conchylicultor/DeepQA/master/data/cornell/movie_lines.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34641919 (33M) [text/plain]\n",
      "Saving to: ‘movie_lines.txt’\n",
      "\n",
      "movie_lines.txt     100%[===================>]  33.04M  4.74MB/s    in 11s     \n",
      "\n",
      "2019-06-22 18:14:12 (3.01 MB/s) - ‘movie_lines.txt’ saved [34641919/34641919]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! sh download_cornell.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-23 16:38:15--  http://opus.lingfil.uu.se/download.php?f=OpenSubtitles/en.tar.gz\n",
      "Resolving opus.lingfil.uu.se (opus.lingfil.uu.se)... 130.238.78.148\n",
      "Connecting to opus.lingfil.uu.se (opus.lingfil.uu.se)|130.238.78.148|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://opus.nlpl.eu/download.php?f=OpenSubtitles/en.tar.gz [following]\n",
      "--2019-06-23 16:38:15--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/en.tar.gz\n",
      "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
      "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v1/xml/en.zip [following]\n",
      "--2019-06-23 16:38:15--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v1/xml/en.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.0, 86.50.254.1\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 148967861 (142M) [application/zip]\n",
      "Saving to: ‘en.tar.gz’\n",
      "\n",
      "en.tar.gz           100%[===================>] 142.07M  3.17MB/s    in 47s     \n",
      "\n",
      "2019-06-23 16:39:03 (2.99 MB/s) - ‘en.tar.gz’ saved [148967861/148967861]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! sh download_opensubs.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mINFO\u001b[m\u001b[m          \u001b[31mLICENSE\u001b[m\u001b[m       \u001b[34mOpenSubtitles\u001b[m\u001b[m \u001b[31mREADME\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/opensubs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/cornell'\n",
    "max_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:05<00:00, 14642.59it/s]\n"
     ]
    }
   ],
   "source": [
    "data = datasets.readCornellData(dataset_path, max_len=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenSubtitles data files: 100%|██████████| 4637/4637 [00:00<00:00, 1613488.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenSubtitles conversations in data/opensubs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = datasets.readOpensubsData('data/opensubs', max_len=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:08<00:00, 9914.08it/s] \n"
     ]
    }
   ],
   "source": [
    "data = [(preprocess_sentence(a), preprocess_sentence(b)) for (a,b) in create_dataset(num_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5256, 0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "#     w = unicode_to_ascii(w.lower().strip())\n",
    "    w = w.lower().strip()\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "\n",
    "def create_index(phrases):   \n",
    "    \n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    vocab = set()\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        vocab.update(phrase.split(' '))\n",
    "    \n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    word2idx['<pad>'] = 0\n",
    "    for index, word in enumerate(vocab):\n",
    "        word2idx[word] = index + 1\n",
    "    \n",
    "    for word, index in word2idx.items():\n",
    "        idx2word[index] = word\n",
    "        \n",
    "    return word2idx, idx2word, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(num_examples, dataset_name = 'cornell', max_sentence_length= 10):\n",
    "    dataset_path = 'data/{}'.format(dataset_name)\n",
    "\n",
    "    if dataset_name == \"cornell\":\n",
    "        data = datasets.readCornellData(dataset_path, max_len=max_sentence_length)\n",
    "    elif dataset_name == \"opensubs\":\n",
    "        data = datasets.readOpensubsData(dataset_path, max_len=max_sentence_length)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized dataset: {!r}\".format(dataset_name))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "# def preprocess_sentence(s):\n",
    "#     return '<start> ' + s + ' <end>'\n",
    "\n",
    "\n",
    "def load_dataset(num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    pairs = [(preprocess_sentence(a), preprocess_sentence(b)) for (a,b) in create_dataset(num_examples)]\n",
    "\n",
    "    # index language using the class defined above    \n",
    "    word2idx, idx2word, vocab = create_index([p for ps in pairs for p in ps])\n",
    "    # Vectorize the input and target languages\n",
    "    \n",
    "    # question sentences\n",
    "    input_tensor = [[word2idx[w] for w in qs.split(' ')] for qs, a in pairs]\n",
    "    \n",
    "    # answer sentences\n",
    "    target_tensor = [[word2idx[w] for w in a.split(' ')] for q, a in pairs]\n",
    "    \n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
    "                                                                 maxlen=max_length_inp,\n",
    "                                                                 padding='post')\n",
    "    \n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
    "                                                                  maxlen=max_length_tar, \n",
    "                                                                  padding='post')\n",
    "    \n",
    "    return input_tensor, target_tensor, (word2idx, idx2word, vocab), max_length_inp, max_length_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:05<00:00, 14890.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, dict_index, max_length_inp, max_length_targ = load_dataset(num_examples, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4204, 4204, 1052, 1052)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_size = len(dict_index[0])\n",
    "vocab_tar_size = vocab_size\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    if tf.test.is_gpu_available():\n",
    "        return tf.keras.layers.CuDNNGRU(units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    else:\n",
    "        return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_index[0]['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training explained\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4769\n",
      "Epoch 1 Loss 1.5263\n",
      "Time taken for 1 epoch 221.04495096206665 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.3829\n",
      "Epoch 2 Loss 1.4485\n",
      "Time taken for 1 epoch 211.28798985481262 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5323\n",
      "Epoch 3 Loss 1.3965\n",
      "Time taken for 1 epoch 211.8134160041809 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.2901\n",
      "Epoch 4 Loss 1.3429\n",
      "Time taken for 1 epoch 218.80016374588013 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.2519\n",
      "Epoch 5 Loss 1.2952\n",
      "Time taken for 1 epoch 227.82110285758972 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([word2idx['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.3679\n",
      "Epoch 1 Loss 1.2502\n",
      "Time taken for 1 epoch 177.2892951965332 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1577\n",
      "Epoch 2 Loss 1.2095\n",
      "Time taken for 1 epoch 194.33765125274658 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2058\n",
      "Epoch 3 Loss 1.1729\n",
      "Time taken for 1 epoch 168.82328701019287 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.1595\n",
      "Epoch 4 Loss 1.1229\n",
      "Time taken for 1 epoch 178.12910199165344 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0668\n",
      "Epoch 5 Loss 1.0761\n",
      "Time taken for 1 epoch 181.23971509933472 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.0227\n",
      "Epoch 6 Loss 1.0211\n",
      "Time taken for 1 epoch 168.97692489624023 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.9472\n",
      "Epoch 7 Loss 0.9687\n",
      "Time taken for 1 epoch 170.32097911834717 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.8261\n",
      "Epoch 8 Loss 0.9197\n",
      "Time taken for 1 epoch 165.8781189918518 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8883\n",
      "Epoch 9 Loss 0.8649\n",
      "Time taken for 1 epoch 169.77385807037354 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7643\n",
      "Epoch 10 Loss 0.8175\n",
      "Time taken for 1 epoch 198.46596884727478 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.7243\n",
      "Epoch 11 Loss 0.7721\n",
      "Time taken for 1 epoch 255.14657282829285 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.6361\n",
      "Epoch 12 Loss 0.7228\n",
      "Time taken for 1 epoch 168.70337581634521 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.6376\n",
      "Epoch 13 Loss 0.6662\n",
      "Time taken for 1 epoch 172.0539219379425 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4671\n",
      "Epoch 14 Loss 0.6238\n",
      "Time taken for 1 epoch 170.55512619018555 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.6265\n",
      "Epoch 15 Loss 0.5845\n",
      "Time taken for 1 epoch 165.84952974319458 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.5514\n",
      "Epoch 16 Loss 0.5448\n",
      "Time taken for 1 epoch 171.84690833091736 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.4692\n",
      "Epoch 17 Loss 0.5040\n",
      "Time taken for 1 epoch 164.76511001586914 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.3889\n",
      "Epoch 18 Loss 0.4720\n",
      "Time taken for 1 epoch 176.3829047679901 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.3017\n",
      "Epoch 19 Loss 0.4444\n",
      "Time taken for 1 epoch 181.53107595443726 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.3164\n",
      "Epoch 20 Loss 0.4213\n",
      "Time taken for 1 epoch 197.028244972229 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([word2idx['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction \n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, dictionary_index,  max_length):\n",
    "    word2idx = dictionary_index[0]\n",
    "    idx2word = dictionary_index[1]\n",
    "    attention_plot = np.zeros((max_length, max_length))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [word2idx[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([word2idx['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2word[predicted_id] + ' '\n",
    "\n",
    "        if idx2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(sentence, encoder, decoder, dictionary_index, max_length):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, dictionary_index, max_length)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x1a4bf97128>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hello <end>\n",
      "Predicted translation: hello <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer('Hello', encoder, decoder, dict_index, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how are you doing <end>\n",
      "Predicted translation: im bored <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer('How are you doing', encoder, decoder, dict_index, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what do you like <end>\n",
      "Predicted translation: what <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer('what do you like', encoder, decoder, dict_index, max_length_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_inp, max_length_targ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  36, 2430, 1597,   35,    0,    0], dtype=int32),\n",
       " array([1, 1, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train[0], 1 - np.equal(target_tensor_train[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  36, 1580,   35,    0,    0], dtype=int32),\n",
       " array([  36, 2430, 1597,   35,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0], target_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1861"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_index = create_index([q for q, a in data])\n",
    "q_word2idx = q_index[0]\n",
    "len(q_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1618],\n",
       " [1823],\n",
       " [1471, 1202],\n",
       " [1781],\n",
       " [813, 1097],\n",
       " [1626],\n",
       " [1202],\n",
       " [1576, 776, 449],\n",
       " [1781],\n",
       " [465],\n",
       " [449, 1770],\n",
       " [1781],\n",
       " [1845, 1353, 1521],\n",
       " [1784],\n",
       " [546],\n",
       " [1613, 479],\n",
       " [1162],\n",
       " [1845, 1622],\n",
       " [1427, 811],\n",
       " [1162],\n",
       " [1629],\n",
       " [1162, 1162, 1753],\n",
       " [1316],\n",
       " [76],\n",
       " [76],\n",
       " [76],\n",
       " [76],\n",
       " [723, 749],\n",
       " [1612, 648],\n",
       " [760, 1745, 811],\n",
       " [1358],\n",
       " [682],\n",
       " [1128],\n",
       " [1834],\n",
       " [819],\n",
       " [713],\n",
       " [726, 813, 1035],\n",
       " [723],\n",
       " [1767, 1425],\n",
       " [648, 973],\n",
       " [15, 13],\n",
       " [1483],\n",
       " [348],\n",
       " [1779, 1207],\n",
       " [105],\n",
       " [1684],\n",
       " [934, 969],\n",
       " [1602, 1035],\n",
       " [776, 969, 1845],\n",
       " [713],\n",
       " [724, 1702],\n",
       " [1522],\n",
       " [1715, 612],\n",
       " [246, 384],\n",
       " [1787, 821],\n",
       " [1303, 1808],\n",
       " [1727],\n",
       " [1358],\n",
       " [1619, 1406],\n",
       " [1405, 1206],\n",
       " [1834],\n",
       " [449, 1770],\n",
       " [1770, 1617],\n",
       " [813, 1570],\n",
       " [1162],\n",
       " [1840],\n",
       " [1202],\n",
       " [648, 1781],\n",
       " [1845, 1202],\n",
       " [1845, 1202],\n",
       " [588, 811],\n",
       " [863, 449, 811],\n",
       " [1834],\n",
       " [154],\n",
       " [1388],\n",
       " [1781],\n",
       " [1678],\n",
       " [1087],\n",
       " [67],\n",
       " [385],\n",
       " [653, 811],\n",
       " [1160],\n",
       " [590],\n",
       " [843],\n",
       " [1207],\n",
       " [1474],\n",
       " [1235],\n",
       " [484],\n",
       " [500],\n",
       " [500],\n",
       " [1459],\n",
       " [1178],\n",
       " [1848, 1576],\n",
       " [500],\n",
       " [1599],\n",
       " [726],\n",
       " [1387],\n",
       " [1387],\n",
       " [1845, 1202],\n",
       " [791, 1618],\n",
       " [719],\n",
       " [1176],\n",
       " [1483],\n",
       " [1547],\n",
       " [1105],\n",
       " [786, 641],\n",
       " [1502],\n",
       " [1424, 811],\n",
       " [954],\n",
       " [1777],\n",
       " [791, 25, 691],\n",
       " [1772, 1611],\n",
       " [25, 228],\n",
       " [1178],\n",
       " [1840],\n",
       " [1770],\n",
       " [1639],\n",
       " [491],\n",
       " [1840],\n",
       " [1162],\n",
       " [1222],\n",
       " [1649],\n",
       " [73],\n",
       " [167, 267],\n",
       " [174],\n",
       " [723],\n",
       " [174],\n",
       " [1704],\n",
       " [1840, 793],\n",
       " [1330],\n",
       " [1840],\n",
       " [1840],\n",
       " [1162],\n",
       " [1193, 1840],\n",
       " [1613, 573],\n",
       " [776, 1622, 1521],\n",
       " [1777],\n",
       " [1770],\n",
       " [1107, 873],\n",
       " [323],\n",
       " [293],\n",
       " [164],\n",
       " [66],\n",
       " [1189, 356],\n",
       " [246],\n",
       " [1162],\n",
       " [1162, 1770],\n",
       " [1162],\n",
       " [1162],\n",
       " [1162, 1770],\n",
       " [1840],\n",
       " [819],\n",
       " [1202],\n",
       " [1375],\n",
       " [1834],\n",
       " [819],\n",
       " [409],\n",
       " [726, 819],\n",
       " [1162],\n",
       " [1840, 1576],\n",
       " [703, 698],\n",
       " [291],\n",
       " [1763],\n",
       " [1178],\n",
       " [689, 1178],\n",
       " [1840],\n",
       " [711],\n",
       " [1840, 1502],\n",
       " [808, 811, 1404],\n",
       " [1582],\n",
       " [391],\n",
       " [1770, 1613],\n",
       " [1079],\n",
       " [1755, 414],\n",
       " [1767, 478],\n",
       " [984, 1294],\n",
       " [738],\n",
       " [461, 1582],\n",
       " [1251],\n",
       " [1521, 722, 1810],\n",
       " [1329],\n",
       " [497],\n",
       " [1258],\n",
       " [1840],\n",
       " [1774],\n",
       " [1770, 808, 811],\n",
       " [1258],\n",
       " [588, 811],\n",
       " [1533],\n",
       " [1792],\n",
       " [1781],\n",
       " [329],\n",
       " [1845, 1576],\n",
       " [1176],\n",
       " [719, 1754, 641],\n",
       " [616],\n",
       " [1062],\n",
       " [703, 895],\n",
       " [1840],\n",
       " [1840],\n",
       " [167, 267],\n",
       " [1840],\n",
       " [1840],\n",
       " [167, 267],\n",
       " [272],\n",
       " [1840, 160],\n",
       " [167, 267],\n",
       " [1840, 160],\n",
       " [788, 1533],\n",
       " [887, 1035],\n",
       " [1119, 1528],\n",
       " [1445, 161],\n",
       " [722, 119],\n",
       " [215],\n",
       " [1359],\n",
       " [891],\n",
       " [194],\n",
       " [416],\n",
       " [969],\n",
       " [584],\n",
       " [1134],\n",
       " [1313],\n",
       " [1449],\n",
       " [969],\n",
       " [752],\n",
       " [969],\n",
       " [556],\n",
       " [969],\n",
       " [1162, 1609],\n",
       " [1556],\n",
       " [1220],\n",
       " [1845, 576],\n",
       " [663, 264],\n",
       " [1612, 811],\n",
       " [1373],\n",
       " [1772, 1627],\n",
       " [1781],\n",
       " [417],\n",
       " [808, 703],\n",
       " [723],\n",
       " [776, 1426, 811],\n",
       " [225],\n",
       " [835],\n",
       " [726],\n",
       " [575],\n",
       " [798],\n",
       " [422],\n",
       " [1037],\n",
       " [1003],\n",
       " [1002],\n",
       " [25, 628],\n",
       " [703, 788, 1091],\n",
       " [1162],\n",
       " [113],\n",
       " [25, 964],\n",
       " [1843, 1770],\n",
       " [92],\n",
       " [1245],\n",
       " [1375],\n",
       " [1112],\n",
       " [1032],\n",
       " [1032, 1770],\n",
       " [1840],\n",
       " [1104, 729],\n",
       " [1834],\n",
       " [590],\n",
       " [1733],\n",
       " [1781, 927],\n",
       " [198],\n",
       " [786],\n",
       " [1202],\n",
       " [1358],\n",
       " [384],\n",
       " [384],\n",
       " [1613, 1379],\n",
       " [934, 1627],\n",
       " [1845, 1427],\n",
       " [1193, 1193],\n",
       " [1080],\n",
       " [1087],\n",
       " [1840, 776, 893],\n",
       " [648],\n",
       " [1193, 1176],\n",
       " [1588],\n",
       " [600],\n",
       " [1770],\n",
       " [537, 1035],\n",
       " [1771],\n",
       " [788, 1533],\n",
       " [95],\n",
       " [726],\n",
       " [745, 1483],\n",
       " [182],\n",
       " [1770, 808, 811],\n",
       " [1135],\n",
       " [723],\n",
       " [745, 1483],\n",
       " [1772, 1627],\n",
       " [1152],\n",
       " [1553, 811],\n",
       " [788, 1533],\n",
       " [1767, 791],\n",
       " [788, 89],\n",
       " [1777],\n",
       " [934, 1770],\n",
       " [1326],\n",
       " [1326],\n",
       " [831],\n",
       " [1834],\n",
       " [414],\n",
       " [1609],\n",
       " [194],\n",
       " [461, 1104],\n",
       " [1189, 356],\n",
       " [171],\n",
       " [726],\n",
       " [223],\n",
       " [335, 1777],\n",
       " [1162, 788, 963],\n",
       " [1845, 461],\n",
       " [1733, 1733],\n",
       " [1770, 808, 811],\n",
       " [813, 1271],\n",
       " [1162],\n",
       " [1733, 1733],\n",
       " [25, 1793],\n",
       " [1840],\n",
       " [811, 452],\n",
       " [1189, 356],\n",
       " [1840],\n",
       " [40],\n",
       " [1770],\n",
       " [1618],\n",
       " [1689, 40],\n",
       " [1840, 811, 808],\n",
       " [1770],\n",
       " [25, 265],\n",
       " [1840, 1502],\n",
       " [251, 1662],\n",
       " [1189, 1770],\n",
       " [713],\n",
       " [501, 1528],\n",
       " [1162],\n",
       " [1834],\n",
       " [648, 642],\n",
       " [1613, 955],\n",
       " [1642, 641, 1702],\n",
       " [1193, 1162],\n",
       " [258],\n",
       " [1751, 1627],\n",
       " [726, 749],\n",
       " [258],\n",
       " [1162],\n",
       " [1754, 449],\n",
       " [1840],\n",
       " [1642, 173],\n",
       " [1193, 1162],\n",
       " [40],\n",
       " [1777],\n",
       " [834],\n",
       " [1763],\n",
       " [457],\n",
       " [1162],\n",
       " [959],\n",
       " [1162],\n",
       " [335, 791],\n",
       " [1193, 1162],\n",
       " [641, 1777],\n",
       " [726, 384],\n",
       " [76],\n",
       " [1202, 1202],\n",
       " [1202],\n",
       " [641, 56],\n",
       " [1417],\n",
       " [1162, 984, 1162],\n",
       " [606],\n",
       " [1035, 1702, 1613],\n",
       " [723, 1117],\n",
       " [1142],\n",
       " [25, 191],\n",
       " [1193, 1119, 642],\n",
       " [713],\n",
       " [713],\n",
       " [1840],\n",
       " [1845, 559],\n",
       " [760, 1111],\n",
       " [1840, 776, 449],\n",
       " [1387],\n",
       " [703, 437],\n",
       " [1162, 788, 1174],\n",
       " [1840, 703, 437],\n",
       " [613, 1001],\n",
       " [1770],\n",
       " [1770, 1770],\n",
       " [1840, 776, 437],\n",
       " [1840, 776, 449],\n",
       " [1429],\n",
       " [742, 1206],\n",
       " [1840],\n",
       " [1107, 716],\n",
       " [335, 1206, 791],\n",
       " [813, 954],\n",
       " [1502],\n",
       " [340],\n",
       " [1845, 475],\n",
       " [1840],\n",
       " [813, 1035],\n",
       " [1193, 1483],\n",
       " [1492, 1035],\n",
       " [1107, 1145],\n",
       " [1846, 1104],\n",
       " [1617, 1774],\n",
       " [1228],\n",
       " [776, 1812],\n",
       " [650],\n",
       " [650],\n",
       " [787, 776],\n",
       " [1412],\n",
       " [1770, 587],\n",
       " [1119, 1192],\n",
       " [213],\n",
       " [1590, 811],\n",
       " [1642, 1797],\n",
       " [242],\n",
       " [726],\n",
       " [1612, 811],\n",
       " [722, 647],\n",
       " [1684],\n",
       " [729],\n",
       " [1770],\n",
       " [1228],\n",
       " [498],\n",
       " [1781, 1745, 703],\n",
       " [788, 1533],\n",
       " [808, 811, 1840],\n",
       " [1840],\n",
       " [449, 1845],\n",
       " [1781],\n",
       " [701, 776],\n",
       " [632],\n",
       " [462],\n",
       " [595],\n",
       " [1193, 1834],\n",
       " [1104, 811],\n",
       " [1231, 1618],\n",
       " [1845, 438],\n",
       " [1774],\n",
       " [178],\n",
       " [1772, 1627],\n",
       " [1164],\n",
       " [1612, 1188],\n",
       " [654, 641],\n",
       " [1162, 1322],\n",
       " [1533],\n",
       " [837],\n",
       " [1193, 726, 1087],\n",
       " [1612, 811],\n",
       " [723],\n",
       " [460],\n",
       " [92, 1770],\n",
       " [723],\n",
       " [1162, 593],\n",
       " [1396],\n",
       " [1109, 918],\n",
       " [726],\n",
       " [726],\n",
       " [1202],\n",
       " [1834],\n",
       " [388],\n",
       " [1770],\n",
       " [1684, 639],\n",
       " [723, 1845],\n",
       " [1845, 1819],\n",
       " [1207, 1218, 1676],\n",
       " [1840],\n",
       " [1770, 808, 811],\n",
       " [461],\n",
       " [1854],\n",
       " [1855],\n",
       " [713],\n",
       " [1119, 1128, 808],\n",
       " [1119, 746],\n",
       " [1792],\n",
       " [1358],\n",
       " [1440],\n",
       " [53],\n",
       " [966],\n",
       " [27, 1348],\n",
       " [246, 1770],\n",
       " [246],\n",
       " [1493, 1702],\n",
       " [813, 993],\n",
       " [1398],\n",
       " [251, 920],\n",
       " [251, 1533],\n",
       " [27],\n",
       " [1466, 772],\n",
       " [715],\n",
       " [882, 882],\n",
       " [788, 1533],\n",
       " [1792],\n",
       " [813, 1202],\n",
       " [1834],\n",
       " [1774],\n",
       " [1844, 740, 740],\n",
       " [1097],\n",
       " [726, 1618],\n",
       " [251, 847],\n",
       " [1834],\n",
       " [1774],\n",
       " [726],\n",
       " [726],\n",
       " [210],\n",
       " [1193],\n",
       " [1772, 1627],\n",
       " [1021],\n",
       " [319],\n",
       " [776, 461],\n",
       " [745, 1483],\n",
       " [1770],\n",
       " [1770],\n",
       " [70],\n",
       " [1509],\n",
       " [1274],\n",
       " [1840, 1502],\n",
       " [1759],\n",
       " [1770, 808, 811],\n",
       " [703, 438],\n",
       " [1848, 755],\n",
       " [1564, 811],\n",
       " [1779, 1745],\n",
       " [490, 1090],\n",
       " [726, 221],\n",
       " [723, 1349],\n",
       " [1303, 675],\n",
       " [71, 1375],\n",
       " [1126],\n",
       " [1792],\n",
       " [1290],\n",
       " [1430],\n",
       " [1195],\n",
       " [1770],\n",
       " [335, 1206],\n",
       " [722, 414],\n",
       " [1770],\n",
       " [611],\n",
       " [590, 463],\n",
       " [1676],\n",
       " [1217],\n",
       " [358],\n",
       " [760, 1004],\n",
       " [743, 590],\n",
       " [1029],\n",
       " [1461],\n",
       " [1160],\n",
       " [1461],\n",
       " [496, 303],\n",
       " [715, 1041],\n",
       " [1193, 841],\n",
       " [742, 811],\n",
       " [990],\n",
       " [1781],\n",
       " [1840],\n",
       " [1805, 1035],\n",
       " [224],\n",
       " [47],\n",
       " [564],\n",
       " [696],\n",
       " [1770],\n",
       " [591],\n",
       " [1777, 1642],\n",
       " [1483],\n",
       " [1770],\n",
       " [537, 1035],\n",
       " [1770],\n",
       " [1323],\n",
       " [1193, 1119, 642],\n",
       " [567],\n",
       " [819],\n",
       " [1009],\n",
       " [776, 679, 1642],\n",
       " [776, 969, 1845],\n",
       " [1083],\n",
       " [1083],\n",
       " [179, 1233],\n",
       " [776, 653, 1642],\n",
       " [1787, 1627],\n",
       " [791, 708],\n",
       " [1475, 414],\n",
       " [1781, 509],\n",
       " [437, 703],\n",
       " [776, 1325],\n",
       " [776, 1325],\n",
       " [788, 1533],\n",
       " [1451, 1829],\n",
       " [1372],\n",
       " [349],\n",
       " [1208],\n",
       " [343],\n",
       " [449, 1845],\n",
       " [317],\n",
       " [1770, 1770],\n",
       " [1702],\n",
       " [1754, 1315],\n",
       " [1498],\n",
       " [776, 1427],\n",
       " [1772, 1611],\n",
       " [696],\n",
       " [1207, 1097],\n",
       " [1027],\n",
       " [1770],\n",
       " [1027],\n",
       " [1387],\n",
       " [1387],\n",
       " [1519],\n",
       " [1770],\n",
       " [625, 1702],\n",
       " [1848, 909],\n",
       " [723],\n",
       " [813, 612],\n",
       " [1781],\n",
       " [1781],\n",
       " [637, 1702],\n",
       " [1840],\n",
       " [246, 776, 262],\n",
       " [1763, 1840],\n",
       " [726, 855],\n",
       " [726, 517],\n",
       " [1770, 1792],\n",
       " [855],\n",
       " [641, 56],\n",
       " [1770, 1635],\n",
       " [1476],\n",
       " [1358],\n",
       " [1684, 713],\n",
       " [726, 813, 1035],\n",
       " [210],\n",
       " [1464],\n",
       " [648, 973],\n",
       " [776, 1812],\n",
       " [648, 973],\n",
       " [788, 1350],\n",
       " [1356],\n",
       " [92, 1331],\n",
       " [649],\n",
       " [1781],\n",
       " [1082],\n",
       " [788, 1457],\n",
       " [665],\n",
       " [713],\n",
       " [1162],\n",
       " [449, 1845],\n",
       " [1840],\n",
       " [776, 449],\n",
       " [1770, 808, 811],\n",
       " [1611, 1808],\n",
       " [500],\n",
       " [625, 1231],\n",
       " [246, 500],\n",
       " [177],\n",
       " [1840],\n",
       " [177],\n",
       " [176],\n",
       " [1840, 776, 80],\n",
       " [177],\n",
       " [1193, 1162],\n",
       " [1845, 461],\n",
       " [1162],\n",
       " [1608, 1845],\n",
       " [474],\n",
       " [1162],\n",
       " [1193, 1119, 642],\n",
       " [1840],\n",
       " [177],\n",
       " [1608, 1845],\n",
       " [177],\n",
       " [1178],\n",
       " [177],\n",
       " [1613, 1181],\n",
       " [1763],\n",
       " [177],\n",
       " [1770],\n",
       " [1193, 1119, 642],\n",
       " [1193],\n",
       " [1840, 776, 449],\n",
       " [1770, 1207],\n",
       " [1618],\n",
       " [722, 119],\n",
       " [1375],\n",
       " [1162],\n",
       " [1840],\n",
       " [121, 332],\n",
       " [115],\n",
       " [1162],\n",
       " [1162],\n",
       " [788, 863],\n",
       " [1820],\n",
       " [1763],\n",
       " [1642, 167, 1770],\n",
       " [1193, 1162],\n",
       " [776, 1794],\n",
       " [246, 1792],\n",
       " [1174, 1178],\n",
       " [1162],\n",
       " [814, 1339],\n",
       " [1611],\n",
       " [1845],\n",
       " [1193, 1817],\n",
       " [110, 1845],\n",
       " [1770],\n",
       " [1189, 356],\n",
       " [645],\n",
       " [1193],\n",
       " [1840, 1638],\n",
       " [1618],\n",
       " [776, 893],\n",
       " [776, 262],\n",
       " [1634, 1617],\n",
       " [1162, 451],\n",
       " [1600],\n",
       " [1098],\n",
       " [1098],\n",
       " [1638],\n",
       " [1098],\n",
       " [1845],\n",
       " [1845],\n",
       " [1098],\n",
       " [1840],\n",
       " [1193, 1162],\n",
       " [45],\n",
       " [1119, 1528],\n",
       " [1763, 1684, 1162],\n",
       " [1400],\n",
       " [1076],\n",
       " [703, 1368],\n",
       " [1777],\n",
       " [1400, 442],\n",
       " [430],\n",
       " [1162, 1483],\n",
       " [1174, 1035],\n",
       " [182],\n",
       " [1733],\n",
       " [1325],\n",
       " [1089],\n",
       " [1035],\n",
       " [1845],\n",
       " [587, 1770],\n",
       " [713],\n",
       " [713],\n",
       " [516],\n",
       " [392],\n",
       " [384],\n",
       " [1781, 1745, 811],\n",
       " [1087],\n",
       " [1772, 1627],\n",
       " [444],\n",
       " [1162],\n",
       " [1613, 451],\n",
       " [1162],\n",
       " [1215],\n",
       " [1162, 1162],\n",
       " [625, 1702],\n",
       " [414],\n",
       " [1772, 1627],\n",
       " [449, 811],\n",
       " [1834],\n",
       " [1754, 1191],\n",
       " [1162],\n",
       " [25, 601],\n",
       " [1772, 1641],\n",
       " [1023],\n",
       " [1162],\n",
       " [1837],\n",
       " [1162],\n",
       " [71, 1375],\n",
       " [694],\n",
       " [959],\n",
       " [1202],\n",
       " [1189, 356],\n",
       " [1804, 642],\n",
       " [1025],\n",
       " [1840],\n",
       " [1193, 694],\n",
       " [694],\n",
       " [1840],\n",
       " [1248],\n",
       " [859],\n",
       " [1608, 1845],\n",
       " [1120],\n",
       " [1840],\n",
       " [1010],\n",
       " [328],\n",
       " [1566],\n",
       " [734, 1035],\n",
       " [859],\n",
       " [1303, 142],\n",
       " [859],\n",
       " [1526],\n",
       " [788, 774],\n",
       " [910],\n",
       " [907],\n",
       " [1763],\n",
       " [1483],\n",
       " [859],\n",
       " [1781, 1745, 811],\n",
       " [764],\n",
       " [863, 1524],\n",
       " [1289, 1524],\n",
       " [1787, 1618],\n",
       " [184, 759],\n",
       " [1845, 934],\n",
       " [1577],\n",
       " [109, 1845, 1201],\n",
       " [569],\n",
       " [722, 647],\n",
       " [1840],\n",
       " [1193, 1162],\n",
       " [251],\n",
       " [69],\n",
       " [1772, 1148],\n",
       " [1292, 811],\n",
       " [1119, 152],\n",
       " [1770],\n",
       " [723, 157],\n",
       " [1193, 726],\n",
       " [1380],\n",
       " [1483],\n",
       " [726],\n",
       " [1770],\n",
       " [713],\n",
       " [1162, 246],\n",
       " [776, 1036, 811],\n",
       " [1834],\n",
       " [788, 1719],\n",
       " [315],\n",
       " [1321],\n",
       " [1792, 1174],\n",
       " [625, 1231],\n",
       " [550, 132],\n",
       " [1847, 1128],\n",
       " [1401],\n",
       " [1583],\n",
       " [72, 1035],\n",
       " [728],\n",
       " [1840],\n",
       " [237, 1190],\n",
       " [1523],\n",
       " [1523],\n",
       " [197],\n",
       " [1781, 1804],\n",
       " [1770],\n",
       " [1609],\n",
       " [1107, 1796],\n",
       " [130, 606],\n",
       " [599],\n",
       " [935],\n",
       " [1162],\n",
       " [1715, 1763],\n",
       " [1324],\n",
       " [458],\n",
       " [1845, 449],\n",
       " [1840],\n",
       " [580],\n",
       " [1733],\n",
       " [1102],\n",
       " [1839],\n",
       " [1286],\n",
       " [1202],\n",
       " [379],\n",
       " [1770, 808],\n",
       " [587, 1781],\n",
       " [726],\n",
       " [1666, 1035],\n",
       " [1487],\n",
       " [256, 811],\n",
       " [1770, 243],\n",
       " [776, 474],\n",
       " [1792],\n",
       " [915, 1178],\n",
       " [1804, 1616],\n",
       " [766],\n",
       " [1723],\n",
       " [164],\n",
       " [1617, 1770],\n",
       " [1770],\n",
       " [1840, 776, 80],\n",
       " [436],\n",
       " [436],\n",
       " [1162, 538],\n",
       " [1011],\n",
       " [1119, 1393],\n",
       " [384],\n",
       " [1763, 1684],\n",
       " [384],\n",
       " [1770],\n",
       " [384],\n",
       " [1770],\n",
       " [1564],\n",
       " [1770],\n",
       " [384],\n",
       " [1356],\n",
       " [246, 794],\n",
       " [470, 854],\n",
       " [25, 1770],\n",
       " [776, 262],\n",
       " [776, 625, 811],\n",
       " [1781, 1745, 811],\n",
       " [1035],\n",
       " [1781],\n",
       " [62],\n",
       " [1840],\n",
       " [1834],\n",
       " [1781, 80, 776],\n",
       " [1572, 1616],\n",
       " [1781, 437],\n",
       " [647, 1777],\n",
       " [1178, 1770],\n",
       " [1613, 168],\n",
       " [745, 1483],\n",
       " [1587],\n",
       " [1178, 1770],\n",
       " [1613, 1416],\n",
       " [491, 811],\n",
       " [1792, 1174],\n",
       " [171],\n",
       " [1770, 1745],\n",
       " [1733],\n",
       " [1655, 717],\n",
       " [1223],\n",
       " [585, 717],\n",
       " [1206, 1770],\n",
       " [474, 811],\n",
       " [813, 729],\n",
       " [1162],\n",
       " [1193, 776, 262],\n",
       " [1375],\n",
       " [1609],\n",
       " [1763],\n",
       " [1763, 1770],\n",
       " [1767, 719],\n",
       " [846],\n",
       " [1572, 1781],\n",
       " [1176],\n",
       " [195],\n",
       " [1792],\n",
       " [261, 776, 715],\n",
       " [703, 438],\n",
       " [1162],\n",
       " [1781, 437],\n",
       " [1770, 808, 811],\n",
       " [750, 897],\n",
       " [1792, 1174],\n",
       " [760],\n",
       " [1733],\n",
       " [1840],\n",
       " [726, 749],\n",
       " [726, 385],\n",
       " [1087],\n",
       " [1576, 1777],\n",
       " [1092],\n",
       " [417],\n",
       " [1537, 1423],\n",
       " [16, 1067],\n",
       " [1834],\n",
       " [1162, 1483],\n",
       " [970],\n",
       " [437, 1817],\n",
       " [1162],\n",
       " [1119, 642],\n",
       " [713],\n",
       " [713],\n",
       " [1115],\n",
       " [713, 1369],\n",
       " [1787, 1611],\n",
       " [936, 1702],\n",
       " [533, 1756],\n",
       " [678, 678],\n",
       " [1107, 1370],\n",
       " [1608, 1845],\n",
       " [1824],\n",
       " [1824],\n",
       " [1198],\n",
       " [1840, 1502],\n",
       " [1107, 1744],\n",
       " [1162],\n",
       " [1193, 1834],\n",
       " [476],\n",
       " [1273],\n",
       " [1746],\n",
       " [1576],\n",
       " [274],\n",
       " [1168],\n",
       " [1107, 651],\n",
       " [331],\n",
       " [776, 80, 846],\n",
       " [1845],\n",
       " [331],\n",
       " [1834],\n",
       " [1858, 634],\n",
       " [776, 437],\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[q_word2idx[w] for w in qs.split(' ')] for qs, a in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('there', 'where'),\n",
       " ('wow', 'lets go'),\n",
       " ('she okay', 'i hope so'),\n",
       " ('who', 'joey'),\n",
       " ('its more', 'expensive'),\n",
       " ('thirtytwo', 'get out'),\n",
       " ('okay', 'im fine im'),\n",
       " ('sure i do', 'why'),\n",
       " ('who', 'dorsey'),\n",
       " ('dorsey', 'i hate him'),\n",
       " ('do what', 'this'),\n",
       " ('who', 'bianca'),\n",
       " ('you re so', 'pleasant'),\n",
       " ('wholesome', 'unwelcome'),\n",
       " ('fallacy', 'the duck'),\n",
       " ('the duck', 'hearsay'),\n",
       " ('no', 'no what'),\n",
       " ('you think', 'oh yeah'),\n",
       " ('say it', 'what'),\n",
       " ('no', 'no'),\n",
       " ('thousands', 'why'),\n",
       " ('no no way', 'but its'),\n",
       " ('pretty', 'hmmmm'),\n",
       " ('alright', 'alright'),\n",
       " ('alright', 'alright'),\n",
       " ('alright', 'alright'),\n",
       " ('alright', 'okay'),\n",
       " ('hey honey', 'hey'),\n",
       " ('thats good', 'yeah'),\n",
       " ('how was it', 'not good'),\n",
       " ('really', 'yes'),\n",
       " ('hal', 'yes'),\n",
       " ('name', 'hammond'),\n",
       " ('yeah', 'vodka'),\n",
       " ('jack', 'yeah'),\n",
       " ('hello', 'hi its me'),\n",
       " ('hi its me', 'fuck you'),\n",
       " ('hey', 'shut up'),\n",
       " ('were saved', 'im fucked'),\n",
       " ('good luck', 'of course'),\n",
       " ('6 5', 'found it'),\n",
       " ('shit', 'what is it'),\n",
       " ('cornelius', 'oh god'),\n",
       " ('which one', 'all 900'),\n",
       " ('apipoussan', 'apipoussan'),\n",
       " ('uh', 'hoppihoppa'),\n",
       " ('like love', 'exactly'),\n",
       " ('tell me', 'i love you'),\n",
       " ('i love you', 'i love you'),\n",
       " ('hello', 'im here'),\n",
       " ('heywake up', 'huh'),\n",
       " ('sobering', 'very funny'),\n",
       " ('very funny', 'alice'),\n",
       " ('but dad', 'now'),\n",
       " ('whos jacob', 'my baby'),\n",
       " ('poor woman', 'no shit'),\n",
       " ('vomit', 'faint'),\n",
       " ('really', 'they said'),\n",
       " ('they said', 'hmm'),\n",
       " ('safety on', 'yeah'),\n",
       " ('yeah', 'this way'),\n",
       " ('do what', 'you know'),\n",
       " ('what then', 'its stupid'),\n",
       " ('its stupid', 'its fun'),\n",
       " ('no', 'no what'),\n",
       " ('yes', 'jesus why'),\n",
       " ('okay', 'fine'),\n",
       " ('good who', 'mel gordon'),\n",
       " ('you okay', 'yeah'),\n",
       " ('you okay', 'yeah'),\n",
       " ('forget it', 'im sorry'),\n",
       " ('just do it', 'attago'),\n",
       " ('yeah', 'bang'),\n",
       " ('bang', 'you and me'),\n",
       " ('rolfe', 'wade'),\n",
       " ('who', 'twombley'),\n",
       " ('twombley', 'no shit'),\n",
       " ('mom', 'yes dear'),\n",
       " ('alice', 'daddy'),\n",
       " ('daddy', 'alice i'),\n",
       " ('got it', 'stay cool'),\n",
       " ('nine', 'any of us'),\n",
       " ('four', 'jim'),\n",
       " ('jim', 'three'),\n",
       " ('one', 'but'),\n",
       " ('shepherd', 'sir'),\n",
       " ('oveur', 'dunn'),\n",
       " ('dunn', 'sir'),\n",
       " ('elaine', 'te'),\n",
       " ('elaine', 'ted'),\n",
       " ('set', 'now'),\n",
       " ('now', 'compute'),\n",
       " ('youre sure', 'im sure'),\n",
       " ('elaine', 'ted'),\n",
       " ('ted', 'yes'),\n",
       " ('hi', 'im randy'),\n",
       " ('roger', 'huh'),\n",
       " ('roger', 'huh'),\n",
       " ('you okay', 'yeah'),\n",
       " ('in there', 'show me')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'<pad>': 0,\n",
       "  'there': 1,\n",
       "  'wow': 2,\n",
       "  'she okay': 3,\n",
       "  'who': 76,\n",
       "  'its more': 5,\n",
       "  'thirtytwo': 6,\n",
       "  'okay': 67,\n",
       "  'sure i do': 8,\n",
       "  'dorsey': 10,\n",
       "  'do what': 62,\n",
       "  'you re so': 13,\n",
       "  'wholesome': 14,\n",
       "  'fallacy': 15,\n",
       "  'the duck': 16,\n",
       "  'no': 65,\n",
       "  'you think': 18,\n",
       "  'say it': 19,\n",
       "  'thousands': 21,\n",
       "  'no no way': 22,\n",
       "  'pretty': 23,\n",
       "  'alright': 27,\n",
       "  'hey honey': 28,\n",
       "  'thats good': 29,\n",
       "  'how was it': 30,\n",
       "  'really': 58,\n",
       "  'hal': 32,\n",
       "  'name': 33,\n",
       "  'yeah': 73,\n",
       "  'jack': 35,\n",
       "  'hello': 50,\n",
       "  'hi its me': 37,\n",
       "  'hey': 38,\n",
       "  'were saved': 39,\n",
       "  'good luck': 40,\n",
       "  '6 5': 41,\n",
       "  'shit': 42,\n",
       "  'cornelius': 43,\n",
       "  'which one': 44,\n",
       "  'apipoussan': 45,\n",
       "  'uh': 46,\n",
       "  'like love': 47,\n",
       "  'tell me': 48,\n",
       "  'i love you': 49,\n",
       "  'heywake up': 51,\n",
       "  'sobering': 52,\n",
       "  'very funny': 53,\n",
       "  'but dad': 54,\n",
       "  'whos jacob': 55,\n",
       "  'poor woman': 56,\n",
       "  'vomit': 57,\n",
       "  'they said': 59,\n",
       "  'safety on': 60,\n",
       "  'what then': 63,\n",
       "  'its stupid': 64,\n",
       "  'yes': 66,\n",
       "  'good who': 68,\n",
       "  'you okay': 99,\n",
       "  'forget it': 71,\n",
       "  'just do it': 72,\n",
       "  'bang': 74,\n",
       "  'rolfe': 75,\n",
       "  'twombley': 77,\n",
       "  'mom': 78,\n",
       "  'alice': 79,\n",
       "  'daddy': 80,\n",
       "  'got it': 81,\n",
       "  'nine': 82,\n",
       "  'four': 83,\n",
       "  'jim': 84,\n",
       "  'one': 85,\n",
       "  'shepherd': 86,\n",
       "  'oveur': 87,\n",
       "  'dunn': 88,\n",
       "  'elaine': 94,\n",
       "  'set': 91,\n",
       "  'now': 92,\n",
       "  'youre sure': 93,\n",
       "  'ted': 95,\n",
       "  'hi': 96,\n",
       "  'roger': 98,\n",
       "  'in there': 100},\n",
       " {0: '<pad>',\n",
       "  1: 'there',\n",
       "  2: 'wow',\n",
       "  3: 'she okay',\n",
       "  76: 'who',\n",
       "  5: 'its more',\n",
       "  6: 'thirtytwo',\n",
       "  67: 'okay',\n",
       "  8: 'sure i do',\n",
       "  10: 'dorsey',\n",
       "  62: 'do what',\n",
       "  13: 'you re so',\n",
       "  14: 'wholesome',\n",
       "  15: 'fallacy',\n",
       "  16: 'the duck',\n",
       "  65: 'no',\n",
       "  18: 'you think',\n",
       "  19: 'say it',\n",
       "  21: 'thousands',\n",
       "  22: 'no no way',\n",
       "  23: 'pretty',\n",
       "  27: 'alright',\n",
       "  28: 'hey honey',\n",
       "  29: 'thats good',\n",
       "  30: 'how was it',\n",
       "  58: 'really',\n",
       "  32: 'hal',\n",
       "  33: 'name',\n",
       "  73: 'yeah',\n",
       "  35: 'jack',\n",
       "  50: 'hello',\n",
       "  37: 'hi its me',\n",
       "  38: 'hey',\n",
       "  39: 'were saved',\n",
       "  40: 'good luck',\n",
       "  41: '6 5',\n",
       "  42: 'shit',\n",
       "  43: 'cornelius',\n",
       "  44: 'which one',\n",
       "  45: 'apipoussan',\n",
       "  46: 'uh',\n",
       "  47: 'like love',\n",
       "  48: 'tell me',\n",
       "  49: 'i love you',\n",
       "  51: 'heywake up',\n",
       "  52: 'sobering',\n",
       "  53: 'very funny',\n",
       "  54: 'but dad',\n",
       "  55: 'whos jacob',\n",
       "  56: 'poor woman',\n",
       "  57: 'vomit',\n",
       "  59: 'they said',\n",
       "  60: 'safety on',\n",
       "  63: 'what then',\n",
       "  64: 'its stupid',\n",
       "  66: 'yes',\n",
       "  68: 'good who',\n",
       "  99: 'you okay',\n",
       "  71: 'forget it',\n",
       "  72: 'just do it',\n",
       "  74: 'bang',\n",
       "  75: 'rolfe',\n",
       "  77: 'twombley',\n",
       "  78: 'mom',\n",
       "  79: 'alice',\n",
       "  80: 'daddy',\n",
       "  81: 'got it',\n",
       "  82: 'nine',\n",
       "  83: 'four',\n",
       "  84: 'jim',\n",
       "  85: 'one',\n",
       "  86: 'shepherd',\n",
       "  87: 'oveur',\n",
       "  88: 'dunn',\n",
       "  94: 'elaine',\n",
       "  91: 'set',\n",
       "  92: 'now',\n",
       "  93: 'youre sure',\n",
       "  95: 'ted',\n",
       "  96: 'hi',\n",
       "  98: 'roger',\n",
       "  100: 'in there'},\n",
       " ['5',\n",
       "  '6',\n",
       "  'alice',\n",
       "  'alright',\n",
       "  'apipoussan',\n",
       "  'bang',\n",
       "  'but',\n",
       "  'cornelius',\n",
       "  'dad',\n",
       "  'daddy',\n",
       "  'do',\n",
       "  'dorsey',\n",
       "  'duck',\n",
       "  'dunn',\n",
       "  'elaine',\n",
       "  'fallacy',\n",
       "  'forget',\n",
       "  'four',\n",
       "  'funny',\n",
       "  'good',\n",
       "  'got',\n",
       "  'hal',\n",
       "  'hello',\n",
       "  'hey',\n",
       "  'heywake',\n",
       "  'hi',\n",
       "  'honey',\n",
       "  'how',\n",
       "  'i',\n",
       "  'in',\n",
       "  'it',\n",
       "  'its',\n",
       "  'jack',\n",
       "  'jacob',\n",
       "  'jim',\n",
       "  'just',\n",
       "  'like',\n",
       "  'love',\n",
       "  'luck',\n",
       "  'me',\n",
       "  'mom',\n",
       "  'more',\n",
       "  'name',\n",
       "  'nine',\n",
       "  'no',\n",
       "  'now',\n",
       "  'okay',\n",
       "  'on',\n",
       "  'one',\n",
       "  'oveur',\n",
       "  'poor',\n",
       "  'pretty',\n",
       "  're',\n",
       "  'really',\n",
       "  'roger',\n",
       "  'rolfe',\n",
       "  'safety',\n",
       "  'said',\n",
       "  'saved',\n",
       "  'say',\n",
       "  'set',\n",
       "  'she',\n",
       "  'shepherd',\n",
       "  'shit',\n",
       "  'so',\n",
       "  'sobering',\n",
       "  'stupid',\n",
       "  'sure',\n",
       "  'ted',\n",
       "  'tell',\n",
       "  'thats',\n",
       "  'the',\n",
       "  'then',\n",
       "  'there',\n",
       "  'they',\n",
       "  'think',\n",
       "  'thirtytwo',\n",
       "  'thousands',\n",
       "  'twombley',\n",
       "  'uh',\n",
       "  'up',\n",
       "  'very',\n",
       "  'vomit',\n",
       "  'was',\n",
       "  'way',\n",
       "  'were',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'wholesome',\n",
       "  'whos',\n",
       "  'woman',\n",
       "  'wow',\n",
       "  'yeah',\n",
       "  'yes',\n",
       "  'you',\n",
       "  'youre'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_index([a for a,b in data[:100]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
